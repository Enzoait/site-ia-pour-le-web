{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\enzoa\\onedrive\\documents\\iim\\ia pour le web\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
    "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
    "DataLoaders](data_tutorial.html) \\|\\|\n",
    "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
    "Model](buildmodel_tutorial.html) \\|\\|\n",
    "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
    "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
    "Model](saveloadrun_tutorial.html)\n",
    "\n",
    "Quickstart\n",
    "==========\n",
    "\n",
    "This section runs through the API for common tasks in machine learning.\n",
    "Refer to the links in each section to dive deeper.\n",
    "\n",
    "Working with data\n",
    "-----------------\n",
    "\n",
    "PyTorch has two [primitives to work with\n",
    "data](https://pytorch.org/docs/stable/data.html):\n",
    "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
    "stores the samples and their corresponding labels, and `DataLoader`\n",
    "wraps an iterable around the `Dataset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch offers domain-specific libraries such as\n",
    "[TorchText](https://pytorch.org/text/stable/index.html),\n",
    "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
    "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
    "include datasets. For this tutorial, we will be using a TorchVision\n",
    "dataset.\n",
    "\n",
    "The `torchvision.datasets` module contains `Dataset` objects for many\n",
    "real-world vision data like CIFAR, COCO ([full list\n",
    "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
    "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
    "includes two arguments: `transform` and `target_transform` to modify the\n",
    "samples and labels respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
    "iterable over our dataset, and supports automatic batching, sampling,\n",
    "shuffling and multiprocess data loading. Here we define a batch size of\n",
    "64, i.e. each element in the dataloader iterable will return a batch of\n",
    "64 features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [loading data in PyTorch](data_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Models\n",
    "===============\n",
    "\n",
    "To define a neural network in PyTorch, we create a class that inherits\n",
    "from\n",
    "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "We define the layers of the network in the `__init__` function and\n",
    "specify how data will pass through the network in the `forward`\n",
    "function. To accelerate operations in the neural network, we move it to\n",
    "the\n",
    "[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "such as CUDA, MPS, MTIA, or XPU. If the current accelerator is\n",
    "available, we will use it. Otherwise, we use the CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [building neural networks in\n",
    "PyTorch](buildmodel_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing the Model Parameters\n",
    "===============================\n",
    "\n",
    "To train a model, we need a [loss\n",
    "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
    "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training\n",
    "dataset (fed to it in batches), and backpropagates the prediction error\n",
    "to adjust the model\\'s parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model\\'s performance against the test dataset to\n",
    "ensure it is learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (*epochs*).\n",
    "During each epoch, the model learns parameters to make better\n",
    "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
    "we\\'d like to see the accuracy increase and the loss decrease with every\n",
    "epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.297088  [   64/60000]\n",
      "loss: 2.291481  [ 6464/60000]\n",
      "loss: 2.293321  [12864/60000]\n",
      "loss: 2.289105  [19264/60000]\n",
      "loss: 2.284795  [25664/60000]\n",
      "loss: 2.280431  [32064/60000]\n",
      "loss: 2.270667  [38464/60000]\n",
      "loss: 2.272440  [44864/60000]\n",
      "loss: 2.264782  [51264/60000]\n",
      "loss: 2.263810  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.255174 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.249995  [   64/60000]\n",
      "loss: 2.241575  [ 6464/60000]\n",
      "loss: 2.256264  [12864/60000]\n",
      "loss: 2.226871  [19264/60000]\n",
      "loss: 2.234700  [25664/60000]\n",
      "loss: 2.230109  [32064/60000]\n",
      "loss: 2.211071  [38464/60000]\n",
      "loss: 2.224363  [44864/60000]\n",
      "loss: 2.200682  [51264/60000]\n",
      "loss: 2.200489  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 2.187831 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.180702  [   64/60000]\n",
      "loss: 2.166942  [ 6464/60000]\n",
      "loss: 2.199394  [12864/60000]\n",
      "loss: 2.132364  [19264/60000]\n",
      "loss: 2.154480  [25664/60000]\n",
      "loss: 2.149029  [32064/60000]\n",
      "loss: 2.112339  [38464/60000]\n",
      "loss: 2.142052  [44864/60000]\n",
      "loss: 2.092309  [51264/60000]\n",
      "loss: 2.090566  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 2.071449 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.062239  [   64/60000]\n",
      "loss: 2.037747  [ 6464/60000]\n",
      "loss: 2.097280  [12864/60000]\n",
      "loss: 1.971392  [19264/60000]\n",
      "loss: 2.010080  [25664/60000]\n",
      "loss: 2.002571  [32064/60000]\n",
      "loss: 1.943400  [38464/60000]\n",
      "loss: 1.998058  [44864/60000]\n",
      "loss: 1.907674  [51264/60000]\n",
      "loss: 1.901835  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 1.873176 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.865340  [   64/60000]\n",
      "loss: 1.822587  [ 6464/60000]\n",
      "loss: 1.914037  [12864/60000]\n",
      "loss: 1.723263  [19264/60000]\n",
      "loss: 1.767921  [25664/60000]\n",
      "loss: 1.754535  [32064/60000]\n",
      "loss: 1.682937  [38464/60000]\n",
      "loss: 1.773905  [44864/60000]\n",
      "loss: 1.632979  [51264/60000]\n",
      "loss: 1.625465  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 1.585438 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [Training your model](optimization_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "=============\n",
    "\n",
    "A common way to save a model is to serialize the internal state\n",
    "dictionary (containing the model parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Models\n",
    "==============\n",
    "\n",
    "The process for loading a model includes re-creating the model structure\n",
    "and loading the state dictionary into it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"8\", Actual: \"8\"\n",
      "Accuracy: 100.0%\n",
      "Loss : 1.3144\n",
      "Predicted: \"1\", Actual: \"3\"\n",
      "Accuracy: 0.0%\n",
      "Loss : 1.7976\n",
      "Predicted: \"2\", Actual: \"2\"\n",
      "Accuracy: 100.0%\n",
      "Loss : 1.4355\n",
      "Predicted: \"1\", Actual: \"1\"\n",
      "Accuracy: 100.0%\n",
      "Loss : 0.7777\n",
      "Predicted: \"5\", Actual: \"5\"\n",
      "Accuracy: 100.0%\n",
      "Loss : 1.7326\n",
      "Predicted: \"2\", Actual: \"2\"\n",
      "Accuracy: 100.0%\n",
      "Loss : 1.2476\n",
      "Predicted: \"10\", Actual: \"5\"\n",
      "Accuracy: 0.0%\n",
      "Loss : 1.8532\n",
      "Predicted: \"10\", Actual: \"10\"\n",
      "Accuracy: 100.0%\n",
      "Loss : 1.7741\n",
      "Predicted: \"7\", Actual: \"6\"\n",
      "Accuracy: 0.0%\n",
      "Loss : 2.3324\n",
      "Predicted: \"8\", Actual: \"10\"\n",
      "Accuracy: 0.0%\n",
      "Loss : 1.4442\n",
      "Pour visualiser dans TensorBoard, lancez :\n",
      "  tensorboard --logdir=runs\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \"10\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "nombre_de_tests = 10\n",
    "\n",
    "for i in range(0, nombre_de_tests):\n",
    "    x, y = test_data[i][0], test_data[i][1]\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        pred = model(x)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "        writer = SummaryWriter()\n",
    "\n",
    "        accuracy = (pred[0].argmax(0) == y).type(torch.float).item()\n",
    "        loss = loss_fn(pred, torch.tensor([y], device=device)).item()\n",
    "\n",
    "        writer.add_scalar('Sample/Accuracy', accuracy, i)\n",
    "        writer.add_scalar('Sample/Loss', loss, i)\n",
    "        writer.add_text('Sample/Prediction', f'Predicted: \"{predicted}\", Actual: \"{actual}\"', i)\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "        print(f'Accuracy: {(100 * accuracy):>0.1f}%')\n",
    "        print(f'Loss : {loss:>0.4f}')\n",
    "\n",
    "        writer = SummaryWriter()\n",
    "        writer.add_scalar('Sample/Accuracy', accuracy, i)\n",
    "        writer.add_scalar('Sample/Loss', loss, i)\n",
    "        writer.add_text('Sample/Prediction', f'Predicted: \"{predicted}\", Actual: \"{actual}\"', i)\n",
    "        writer.close()\n",
    "print(\"Pour visualiser dans TensorBoard, lancez :\\n  tensorboard --logdir=runs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [Saving & Loading your\n",
    "model](saveloadrun_tutorial.html).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
